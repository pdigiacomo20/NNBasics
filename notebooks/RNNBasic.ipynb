{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 09:50:11.469165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-13 09:50:11.868923: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-13 09:50:14.910673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 09:50:14.910852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 09:50:14.910863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trax import fastmath\n",
    "from trax import layers as tl\n",
    "from trax import shapes\n",
    "from trax.fastmath import numpy as jnp  # For use in defining new layer types.\n",
    "from trax.shapes import ShapeDtype\n",
    "from trax.shapes import signature\n",
    "from trax import supervised as ts\n",
    "from trax.supervised import training\n",
    "import trax\n",
    "from trax.fastmath import jax\n",
    "from trax.fastmath import jit\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network AND gate in Trax example with virtual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "#Create virtual data by adding random noise to AND logic\n",
    "x1 = jnp.array([0,1])\n",
    "x2 = jnp.array([1,1])\n",
    "x3 = jnp.array([1,0])\n",
    "x4 = jnp.array([0,0])\n",
    "\n",
    "y1 = jnp.array([0])\n",
    "y2 = jnp.array([1])\n",
    "y3 = jnp.array([0])\n",
    "y4 = jnp.array([0])\n",
    "\n",
    "X = np.empty((40,2))\n",
    "X[0:10,:] = np.random.randn(10,2)*0.1 + x1\n",
    "X[10:20,:] = np.random.randn(10,2)*0.1 + x2\n",
    "X[20:30,:] = np.random.randn(10,2)*0.1 + x3\n",
    "X[30:40,:] = np.random.randn(10,2)*0.1 + x4\n",
    "\n",
    "Y = np.empty((40,1))\n",
    "Y[0:10,:] = np.random.randn(10,1)*0.1 + y1\n",
    "Y[10:20,:] = np.random.randn(10,1)*0.1 + y2\n",
    "Y[20:30,:] = np.random.randn(10,1)*0.1 + y3\n",
    "Y[30:40,:] = np.random.randn(10,1)*0.1 + y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data generator that yields all entries\n",
    "def data_genf(X,Y):\n",
    "    while True:\n",
    "        yield (X,Y)\n",
    "\n",
    "# data_gen = trax.data.inputs.add_loss_weights(data_genf(X,Y))\n",
    "data_gen = data_genf(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tl.Serial(\n",
    "    tl.Dense(2),\n",
    "    tl.activation_fns.Sigmoid(),\n",
    "    tl.Dense(1),\n",
    "    tl.activation_fns.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pd/NNBasics/venv_NNBasics/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py:553: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not write evaluation metrics, because output_dir is None.\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n",
      "Did not save checkpoint as output_dir is None\n"
     ]
    }
   ],
   "source": [
    "train_task = training.TrainTask(\n",
    "    labeled_data= data_gen,\n",
    "    loss_layer = tl.BinaryCrossEntropy(), # A cross-entropy loss function\n",
    "    optimizer = trax.optimizers.Adam(0.01) # The adam optimizer\n",
    ")\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data = data_gen,  # A labeled data generator\n",
    "    metrics = [tl.metrics.L2Loss()], # Evaluate with cross-entropy loss and accuracy\n",
    "    n_eval_batches = 2, # Number of batches to use on each evaluation\n",
    ")\n",
    "training_loop = training.Loop( \n",
    "    model, # A model to train\n",
    "    train_task, # A train task\n",
    ")\n",
    "# Train with train_steps\n",
    "training_loop.run(n_steps = 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01015244]\n",
      "[0.01416808]\n",
      "[0.01609726]\n",
      "[0.88716865]\n"
     ]
    }
   ],
   "source": [
    "print(model(np.array([0,0])))\n",
    "print(model(np.array([0,1])))\n",
    "print(model(np.array([1,0])))\n",
    "print(model(np.array([1,1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra code snippets (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(\n",
    "    trax.data.Shuffle(),\n",
    "    )\n",
    "\n",
    "streamed_batches = data_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12 s ± 62.6 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n",
      "680 ms ± 42.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#shows computational difference between np and jax\n",
    "x = np.random.randn(10000,10000).astype(dtype='float32')\n",
    "def fn(x):\n",
    "    return x.T + x\n",
    "\n",
    "%timeit -n5 fn(x)\n",
    "jax_fn = fn\n",
    "y = jnp.array(x)\n",
    "%timeit jax_fn(y).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02779395])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot construct a dtype from an array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_task \u001b[39m=\u001b[39m training\u001b[39m.\u001b[39mTrainTask( \n\u001b[0;32m----> 2\u001b[0m     labeled_data\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39;49mvstack(X,Y),      \u001b[39m# Use generator (train)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     loss_layer\u001b[39m=\u001b[39mTripletLoss(),        \u001b[39m# Use triplet loss. Don't forget to instantiate this object\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     optimizer\u001b[39m=\u001b[39mtrax\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m),         \u001b[39m# Don't forget to add the learning rate parameter\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     lr_schedule\u001b[39m=\u001b[39mtrax\u001b[39m.\u001b[39mlr\u001b[39m.\u001b[39mwarmup_and_rsqrt_decay(\u001b[39m400\u001b[39m,\u001b[39m0.01\u001b[39m) \u001b[39m# Use Trax multifactor schedule function\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1803\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype)\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1802\u001b[0m   arrs \u001b[39m=\u001b[39m [atleast_2d(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m tup]\n\u001b[0;32m-> 1803\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate(arrs, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1771\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, dtype)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[39m@_wraps\u001b[39m(np\u001b[39m.\u001b[39mconcatenate)\n\u001b[1;32m   1768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcatenate\u001b[39m(arrays: Union[np\u001b[39m.\u001b[39mndarray, Array, Sequence[ArrayLike]],\n\u001b[1;32m   1769\u001b[0m                 axis: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, dtype: Optional[DTypeLike] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m   1770\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arrays, (np\u001b[39m.\u001b[39mndarray, ndarray)):\n\u001b[0;32m-> 1771\u001b[0m     \u001b[39mreturn\u001b[39;00m _concatenate_array(arrays, axis, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1772\u001b[0m   _stackable(\u001b[39m*\u001b[39marrays) \u001b[39mor\u001b[39;00m _check_arraylike(\u001b[39m\"\u001b[39m\u001b[39mconcatenate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39marrays)\n\u001b[1;32m   1773\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(arrays):\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1755\u001b[0m, in \u001b[0;36m_concatenate_array\u001b[0;34m(arr, axis, dtype)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_concatenate_array\u001b[39m(arr: ArrayLike, axis: Optional[\u001b[39mint\u001b[39m],\n\u001b[1;32m   1753\u001b[0m                        dtype: Optional[DTypeLike] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m   1754\u001b[0m   \u001b[39m# Fast path for concatenation when the input is an ndarray rather than a list.\u001b[39;00m\n\u001b[0;32m-> 1755\u001b[0m   arr \u001b[39m=\u001b[39m asarray(arr, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1756\u001b[0m   \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m arr\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1757\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNeed at least one array to concatenate.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2026\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[39m@_wraps\u001b[39m(np\u001b[39m.\u001b[39masarray, lax_description\u001b[39m=\u001b[39m_ARRAY_DOC)\n\u001b[1;32m   2025\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masarray\u001b[39m(a: Any, dtype: Optional[DTypeLike] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, order: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[0;32m-> 2026\u001b[0m   lax_internal\u001b[39m.\u001b[39;49m_check_user_dtype_supported(dtype, \u001b[39m\"\u001b[39;49m\u001b[39masarray\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2027\u001b[0m   dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(dtype) \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype\n\u001b[1;32m   2028\u001b[0m   \u001b[39mreturn\u001b[39;00m array(a, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, order\u001b[39m=\u001b[39morder)\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/jax/_src/lax/lax.py:4808\u001b[0m, in \u001b[0;36m_check_user_dtype_supported\u001b[0;34m(dtype, fun_name)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mtype\u001b[39m) \u001b[39mand\u001b[39;00m dtype \u001b[39min\u001b[39;00m {\u001b[39mbool\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, builtins\u001b[39m.\u001b[39mcomplex}:\n\u001b[1;32m   4807\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 4808\u001b[0m np_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdtype(dtype)\n\u001b[1;32m   4809\u001b[0m \u001b[39mif\u001b[39;00m np_dtype\u001b[39m.\u001b[39mkind \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbiufc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m np_dtype\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m dtypes\u001b[39m.\u001b[39mbfloat16:\n\u001b[1;32m   4810\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mJAX only supports number and bool dtypes, got dtype \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot construct a dtype from an array"
     ]
    }
   ],
   "source": [
    "train_task = training.TrainTask( \n",
    "    labeled_data=jnp.vstack(X,Y),      # Use generator (train)\n",
    "    loss_layer=TripletLoss(),        # Use triplet loss. Don't forget to instantiate this object\n",
    "    optimizer=trax.optimizers.Adam(learning_rate=0.01),         # Don't forget to add the learning rate parameter\n",
    "    lr_schedule=trax.lr.warmup_and_rsqrt_decay(400,0.01) # Use Trax multifactor schedule function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model1 \u001b[39m=\u001b[39m tl\u001b[39m.\u001b[39mSerial(\n\u001b[1;32m      2\u001b[0m     tl\u001b[39m.\u001b[39mEmbedding(vocab_size\u001b[39m=\u001b[39m\u001b[39m8192\u001b[39m, d_feature\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m),\n\u001b[1;32m      3\u001b[0m     tl\u001b[39m.\u001b[39mMean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),  \u001b[39m# Average on axis 1 (length of sentence).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     tl\u001b[39m.\u001b[39mDense(\u001b[39m2\u001b[39m),      \u001b[39m# Classify 2 classes.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     tl\u001b[39m.\u001b[39mLogSoftmax()   \u001b[39m# Produce log-probabilities.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tl' is not defined"
     ]
    }
   ],
   "source": [
    "model1 = tl.Serial(\n",
    "    tl.Embedding(vocab_size=8192, d_feature=256),\n",
    "    tl.Mean(axis=1),  # Average on axis 1 (length of sentence).\n",
    "    tl.Dense(2),      # Classify 2 classes.\n",
    "    tl.LogSoftmax()   # Produce log-probabilities.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tl.Serial(\n",
    "    tl.Dense(2),      # Classify 2 classes.\n",
    "    tl.LogSoftmax()   # Produce log-probabilities.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen1(batch_size,x,y):\n",
    "\n",
    "    m = x.shape[0]\n",
    "    m_inds = [*range(m)]\n",
    "    rnd.shuffle(m_inds)\n",
    "    ind = 0\n",
    "    while True:\n",
    "\n",
    "        X = jnp.empty((batch_size,x.shape[1]))\n",
    "        Y = jnp.empty((batch_size,y.shape[1]))\n",
    "        for i in range(batch_size):\n",
    "            if ind >= m:\n",
    "                ind = 0\n",
    "                rnd.shuffle(m_inds)\n",
    "        \n",
    "            X[i] = x[m_inds[ind],:]\n",
    "            Y[i] = y[m_inds[ind],:]\n",
    "\n",
    "            ind += 1\n",
    "        \n",
    "        yield ((X,Y))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (225004926.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [2], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Y_and =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X_and = jnp.array([])\n",
    "Y_and = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_task \u001b[39m=\u001b[39m ts\u001b[39m.\u001b[39mTrainTask(\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "train_task = ts.TrainTask(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = jnp.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "Yt = jnp.array([[10],[11],[12],[13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen1(2,Xt,Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7., 8.],\n",
       "        [1., 2.]]),\n",
       " array([[13.],\n",
       "        [10.]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TrainTask in module trax.supervised.training:\n",
      "\n",
      "class TrainTask(builtins.object)\n",
      " |  TrainTask(labeled_data, loss_layer, optimizer, lr_schedule=None, n_steps_per_checkpoint=100, n_steps_per_permanent_checkpoint=None, loss_name=None, sample_batch=None, export_prefix=None)\n",
      " |  \n",
      " |  A supervised task (labeled data + feedback mechanism) for training.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, labeled_data, loss_layer, optimizer, lr_schedule=None, n_steps_per_checkpoint=100, n_steps_per_permanent_checkpoint=None, loss_name=None, sample_batch=None, export_prefix=None)\n",
      " |      Configures a training task.\n",
      " |      \n",
      " |      Args:\n",
      " |        labeled_data: Iterator of batches of labeled data tuples. Each tuple has\n",
      " |            1+ data (input value) tensors followed by 1 label (target value)\n",
      " |            tensor.  All tensors are NumPy ndarrays or their JAX counterparts.\n",
      " |        loss_layer: Layer that computes a scalar value (the \"loss\") by comparing\n",
      " |            model output :math:`\\hat{y}=f(x)` to the target :math:`y`.\n",
      " |        optimizer: Optimizer object that computes model weight updates from\n",
      " |            loss-function gradients.\n",
      " |        lr_schedule: Learning rate schedule, a function step -> learning_rate.\n",
      " |        n_steps_per_checkpoint: How many steps to run between checkpoints.\n",
      " |        n_steps_per_permanent_checkpoint: How many steps to run between permanent\n",
      " |            checkpoints.\n",
      " |        loss_name: Name for the loss metric.\n",
      " |        sample_batch: Optional sample batch for model initialization. If not\n",
      " |            provided, it will be taken from ``labeled_data``.\n",
      " |        export_prefix: Optional task name to be used as prefix for exporting\n",
      " |        metrics during training in Loop.\n",
      " |  \n",
      " |  learning_rate(self, step)\n",
      " |      Return the learning rate for the given step.\n",
      " |  \n",
      " |  next_batch(self)\n",
      " |      Returns one batch of labeled data: a tuple of input(s) plus label.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  export_prefix\n",
      " |  \n",
      " |  labeled_data\n",
      " |  \n",
      " |  loss_layer\n",
      " |  \n",
      " |  loss_name\n",
      " |  \n",
      " |  n_steps_per_checkpoint\n",
      " |  \n",
      " |  n_steps_per_permanent_checkpoint\n",
      " |  \n",
      " |  optimizer\n",
      " |  \n",
      " |  sample_batch\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ts.TrainTask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNBasics_venv2",
   "language": "python",
   "name": "nnbasics_venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54933d5d0454cb54ea8cf4e7b3c099269c704adbee2a5b35f5a5ea4d0f5219ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
