{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Transfer Learning for Sentiment Analysis\n",
    "**Objective:** Provide a framework to perform transfer learning using the pre-trained distilBERT model, \n",
    "allowing options for fine-tuning the distilBERT model or simply use its outputs as features. In this example, \n",
    "we use a dataset of Yelp reviews and build a sentiment classifier to identify whether a \n",
    "review is 1 or 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "device = 'cpu'\n",
    "device = 'gpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "**Summary:** parse Yelp reviews for the review text and number of stars associated with that review.\n",
    "Only parse reviews with low or high stars, and ensure that we have an equal number of low and high star reviews. Low star reviews have 1 or 2 stars, and high star reviews have 5 stars.<br /> \n",
    "- *lowstar_review_limit*: once we parse this number of low star reviews have been parsed. Break from processing. Typically there are more high star than low star reviews so the total number of reviews read in will be twice this number. <br /> \n",
    "- *review_limit*: once a total of this number of reviews have been parsed, stop reading in more.<br /> \n",
    "- *sample_per_cat*: sample this many low star and high star reviews respectively from what is parsed.<br /> \n",
    "- *max_num_words*: only parse reviews with number of words less than this length <br /> \n",
    "[Download the data](https://www.yelp.com/dataset/documentation/main) <br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1 star reviews:1024\n",
      "Number of 5 star reviews:1024\n",
      "2047    I don't understand why this place has a line o...\n",
      "1088    I got the gyro \"platter\" for lunch, which was ...\n",
      "1255    Had great reviews. Tried someone new..my husba...\n",
      "1843    Breakfast - burnt pork sausage, very dark almo...\n",
      "1870    I really, really don't like Karaoke.   It's re...\n",
      "Name: _text, dtype: object\n",
      "392    A great place for cheap, ripe produce. Because...\n",
      "966    Actually gabbed a cheesesteak from next door a...\n",
      "376    Hannah is wonderful! I have come to her severa...\n",
      "951    Quaint place for a glass of wine while people ...\n",
      "53     Fantastic food great environment to just shop,...\n",
      "Name: _text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#read-in data\n",
    "lowstar_review_limit = 1024\n",
    "review_limit = np.inf\n",
    "sample_per_cat = 1024\n",
    "max_num_words = 50\n",
    "\n",
    "\n",
    "path = \"/home/pd/datasets/yelp_reviews/yelp_reviews.json\"\n",
    "review_fields_wanted = ['text','lowstar']\n",
    "rev = pd.DataFrame(columns=review_fields_wanted)\n",
    "with open(path,encoding='utf-8') as d:\n",
    "    counter = 0\n",
    "    lowstar_counter = 0\n",
    "    for line in d:\n",
    "        L = json.loads(line)\n",
    "        lowstar = L['stars'] == 1 or (L['stars'] == 2)\n",
    "        fivestar = L['stars'] == 5\n",
    "        not1or5 = not(lowstar or fivestar)\n",
    "        if len(L['text'].split()) > max_num_words or not1or5:\n",
    "            continue\n",
    "        if lowstar:\n",
    "            lowstar_counter += 1\n",
    "            L['lowstar'] = 1\n",
    "        else:\n",
    "            L['lowstar'] = 0\n",
    "        less_fields = {key: L[key] for key in review_fields_wanted }\n",
    "        rev.loc[counter] = less_fields\n",
    "        counter += 1\n",
    "        if counter == review_limit or lowstar_counter == lowstar_review_limit:\n",
    "            break\n",
    "\n",
    "            \n",
    "rev = rev.rename(columns = {'text':'_text','lowstar':'_lowstar'})\n",
    "\n",
    "\n",
    "rev = rev.groupby('_lowstar').apply(lambda x: x.sample(sample_per_cat)).reset_index(drop=True)\n",
    "rev['TARGETS'] = rev['_lowstar']\n",
    "print(f'Number of 1 star reviews:{rev._lowstar[rev._lowstar == 1].count()}')\n",
    "print(f'Number of 5 star reviews:{rev._lowstar[rev._lowstar == 0].count()}')\n",
    "print(rev._text[rev._lowstar == 1].sample(5))\n",
    "print(rev._text[rev._lowstar == 0].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.to_csv('/home/pd/datasets/yelp_reviews/yelp_review_2048.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def dataset\n",
    "class DFToTokenized(Dataset):\n",
    "    def __init__(self,df,tokenizer,max_len):\n",
    "        self.len = len(df)\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        review = ' '.join(self.data['_text'][index].split())\n",
    "        inp = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        tokens = inp['input_ids']\n",
    "        mask = inp['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(tokens, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.TARGETS[index], dtype=torch.uint8)\n",
    "        } \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init train/test params\n",
    "MAX_LEN = 64\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "AUTO_SCALE_GRAD = False\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "train_frac = 0.8\n",
    "train_dataset=rev.sample(frac=train_frac,random_state=200)\n",
    "test_dataset=rev.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "training_set = DFToTokenized(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = DFToTokenized(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "single_params = {'batch_size': 1,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "}\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "single_loader = DataLoader(training_set,**single_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def model\n",
    "class DBertMultiCat(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DBertMultiCat, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#INIT model, loss, optimizer\n",
    "model = DBertMultiCat()\n",
    "for p in model.l1.parameters():\n",
    "    p.requires_grad = False\n",
    "model.to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "params_with_grad = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(params =  params_with_grad, lr=LEARNING_RATE)\n",
    "if AUTO_SCALE_GRAD:\n",
    "    scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train loop def\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0),total=len(training_loader),\n",
    "        position=0, leave=True):\n",
    "\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.uint8)\n",
    "\n",
    "        if AUTO_SCALE_GRAD:\n",
    "            with torch.cpu.amp.autocast():\n",
    "                outputs = model(ids, mask)\n",
    "                loss = loss_function(outputs, targets)\n",
    "        else:\n",
    "            outputs = model(ids, mask)\n",
    "            loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if(AUTO_SCALE_GRAD):\n",
    "            scaler.scale(loss).backward()\n",
    "            # # When using GPU\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<00:55,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.687899649143219\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:02<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 52.747252747252745\n",
      "Training Loss Epoch: 0.6927502017754775\n",
      "Training Accuracy Epoch: 52.747252747252745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:06,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6897991299629211\n",
      "Training Accuracy per 5000 steps: 51.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 53.96825396825397\n",
      "Training Loss Epoch: 0.6895589438768533\n",
      "Training Accuracy Epoch: 53.96825396825397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.694517195224762\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:19<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 56.59340659340659\n",
      "Training Loss Epoch: 0.6890195699838492\n",
      "Training Accuracy Epoch: 56.59340659340659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:13,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7080498337745667\n",
      "Training Accuracy per 5000 steps: 40.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:16<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 55.98290598290598\n",
      "Training Loss Epoch: 0.6872568657765021\n",
      "Training Accuracy Epoch: 55.98290598290598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:12,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6820058822631836\n",
      "Training Accuracy per 5000 steps: 57.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 53.84615384615385\n",
      "Training Loss Epoch: 0.6881257914579831\n",
      "Training Accuracy Epoch: 53.84615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6906676292419434\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 5: 56.28815628815629\n",
      "Training Loss Epoch: 0.6852830465023334\n",
      "Training Accuracy Epoch: 56.28815628815629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6812927722930908\n",
      "Training Accuracy per 5000 steps: 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:30<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 6: 55.61660561660562\n",
      "Training Loss Epoch: 0.6840876249166635\n",
      "Training Accuracy Epoch: 55.61660561660562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:10,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6842745542526245\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:14<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 7: 57.32600732600733\n",
      "Training Loss Epoch: 0.6829985403097593\n",
      "Training Accuracy Epoch: 57.32600732600733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:08,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6744179725646973\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 8: 56.65445665445665\n",
      "Training Loss Epoch: 0.6826992126611563\n",
      "Training Accuracy Epoch: 56.65445665445665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:10,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6916084289550781\n",
      "Training Accuracy per 5000 steps: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 9: 58.42490842490842\n",
      "Training Loss Epoch: 0.6816483438014984\n",
      "Training Accuracy Epoch: 58.42490842490842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:12,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6947983503341675\n",
      "Training Accuracy per 5000 steps: 45.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 10: 57.753357753357754\n",
      "Training Loss Epoch: 0.6786751540807577\n",
      "Training Accuracy Epoch: 57.753357753357754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6780788898468018\n",
      "Training Accuracy per 5000 steps: 57.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 11: 58.66910866910867\n",
      "Training Loss Epoch: 0.6798896376903241\n",
      "Training Accuracy Epoch: 58.66910866910867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6760585308074951\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:19<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 12: 58.73015873015873\n",
      "Training Loss Epoch: 0.6783169141182532\n",
      "Training Accuracy Epoch: 58.73015873015873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:12,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6931607723236084\n",
      "Training Accuracy per 5000 steps: 45.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:14<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 13: 58.05860805860806\n",
      "Training Loss Epoch: 0.6764536568751702\n",
      "Training Accuracy Epoch: 58.05860805860806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6862077713012695\n",
      "Training Accuracy per 5000 steps: 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:14<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 14: 59.95115995115995\n",
      "Training Loss Epoch: 0.6758655126278217\n",
      "Training Accuracy Epoch: 59.95115995115995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:12,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6996618509292603\n",
      "Training Accuracy per 5000 steps: 46.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 15: 59.584859584859586\n",
      "Training Loss Epoch: 0.6741755237946143\n",
      "Training Accuracy Epoch: 59.584859584859586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6771283149719238\n",
      "Training Accuracy per 5000 steps: 57.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 16: 60.195360195360195\n",
      "Training Loss Epoch: 0.6739947497844696\n",
      "Training Accuracy Epoch: 60.195360195360195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:10,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6989840269088745\n",
      "Training Accuracy per 5000 steps: 53.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:12<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 17: 60.317460317460316\n",
      "Training Loss Epoch: 0.6729006423399999\n",
      "Training Accuracy Epoch: 60.317460317460316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:14,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6668469905853271\n",
      "Training Accuracy per 5000 steps: 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:12<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 18: 60.62271062271062\n",
      "Training Loss Epoch: 0.6734807514227353\n",
      "Training Accuracy Epoch: 60.62271062271062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:09,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.651386022567749\n",
      "Training Accuracy per 5000 steps: 65.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:11<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 19: 58.97435897435897\n",
      "Training Loss Epoch: 0.6731648949476389\n",
      "Training Accuracy Epoch: 58.97435897435897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:08,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7033386826515198\n",
      "Training Accuracy per 5000 steps: 46.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:12<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 20: 60.866910866910864\n",
      "Training Loss Epoch: 0.6696507357634031\n",
      "Training Accuracy Epoch: 60.866910866910864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:08,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6836097240447998\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:12<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 21: 60.866910866910864\n",
      "Training Loss Epoch: 0.6700746646294227\n",
      "Training Accuracy Epoch: 60.866910866910864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:10,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6750324964523315\n",
      "Training Accuracy per 5000 steps: 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 22: 59.15750915750916\n",
      "Training Loss Epoch: 0.6726355460973886\n",
      "Training Accuracy Epoch: 59.15750915750916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:12,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6852738261222839\n",
      "Training Accuracy per 5000 steps: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 23: 59.34065934065934\n",
      "Training Loss Epoch: 0.6697726226769961\n",
      "Training Accuracy Epoch: 59.34065934065934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:12,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6852605938911438\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:14<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 24: 61.35531135531136\n",
      "Training Loss Epoch: 0.6651676939083979\n",
      "Training Accuracy Epoch: 61.35531135531136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.66957026720047\n",
      "Training Accuracy per 5000 steps: 67.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 25: 59.21855921855922\n",
      "Training Loss Epoch: 0.6684628656277289\n",
      "Training Accuracy Epoch: 59.21855921855922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:13,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6743199825286865\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:16<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 26: 61.172161172161175\n",
      "Training Loss Epoch: 0.6654344430336585\n",
      "Training Accuracy Epoch: 61.172161172161175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6587346792221069\n",
      "Training Accuracy per 5000 steps: 70.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:18<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 27: 61.233211233211236\n",
      "Training Loss Epoch: 0.6644795330671164\n",
      "Training Accuracy Epoch: 61.233211233211236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:05<02:11,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6700491905212402\n",
      "Training Accuracy per 5000 steps: 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [03:18<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 28: 62.27106227106227\n",
      "Training Loss Epoch: 0.6637566593977121\n",
      "Training Accuracy Epoch: 62.27106227106227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:23<09:54, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7042104601860046\n",
      "Training Accuracy per 5000 steps: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [07:04<00:00, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 29: 59.70695970695971\n",
      "Training Loss Epoch: 0.666911624945127\n",
      "Training Accuracy Epoch: 59.70695970695971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train engine\n",
    "for epoch in range(30):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:15<06:17, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6586676239967346\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [06:10<00:00, 14.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 61.35531135531136\n",
      "Training Loss Epoch: 0.6642708870080801\n",
      "Training Accuracy Epoch: 61.35531135531136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:14<05:55, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6631571650505066\n",
      "Training Accuracy per 5000 steps: 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [06:07<00:00, 14.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 61.47741147741148\n",
      "Training Loss Epoch: 0.6636609595555526\n",
      "Training Accuracy Epoch: 61.47741147741148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:14<05:54, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.644419252872467\n",
      "Training Accuracy per 5000 steps: 71.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [06:07<00:00, 14.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 63.614163614163616\n",
      "Training Loss Epoch: 0.6620221413098849\n",
      "Training Accuracy Epoch: 63.614163614163616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:14<05:52, 14.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6930553913116455\n",
      "Training Accuracy per 5000 steps: 43.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [04:47<00:00, 11.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 61.53846153846154\n",
      "Training Loss Epoch: 0.661240068765787\n",
      "Training Accuracy Epoch: 61.53846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:01,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6759253740310669\n",
      "Training Accuracy per 5000 steps: 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:03<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 63.43101343101343\n",
      "Training Loss Epoch: 0.6595059128908011\n",
      "Training Accuracy Epoch: 63.43101343101343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:01,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6570672988891602\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:05<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 5: 62.637362637362635\n",
      "Training Loss Epoch: 0.6587364879938272\n",
      "Training Accuracy Epoch: 62.637362637362635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:08,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6914713382720947\n",
      "Training Accuracy per 5000 steps: 56.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:32<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 6: 62.39316239316239\n",
      "Training Loss Epoch: 0.6579941236055814\n",
      "Training Accuracy Epoch: 62.39316239316239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:04<01:53,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6604920625686646\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:27<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 7: 62.45421245421245\n",
      "Training Loss Epoch: 0.6579505205154419\n",
      "Training Accuracy Epoch: 62.45421245421245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:22,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6539297103881836\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:34<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 8: 63.43101343101343\n",
      "Training Loss Epoch: 0.6552469271879929\n",
      "Training Accuracy Epoch: 63.43101343101343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:39,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6404223442077637\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:29<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 9: 62.39316239316239\n",
      "Training Loss Epoch: 0.6577477478064023\n",
      "Training Accuracy Epoch: 62.39316239316239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:15,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6698536276817322\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:15<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 10: 61.53846153846154\n",
      "Training Loss Epoch: 0.6591000740344708\n",
      "Training Accuracy Epoch: 61.53846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:14,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6480350494384766\n",
      "Training Accuracy per 5000 steps: 70.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:15<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 11: 63.12576312576313\n",
      "Training Loss Epoch: 0.6510556615315951\n",
      "Training Accuracy Epoch: 63.12576312576313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:15,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6271648406982422\n",
      "Training Accuracy per 5000 steps: 70.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:16<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 12: 62.39316239316239\n",
      "Training Loss Epoch: 0.6543296483846811\n",
      "Training Accuracy Epoch: 62.39316239316239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:15,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6824895739555359\n",
      "Training Accuracy per 5000 steps: 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [03:22<00:00,  7.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 13: 64.22466422466422\n",
      "Training Loss Epoch: 0.6530881936733539\n",
      "Training Accuracy Epoch: 64.22466422466422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:14<05:59, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6391014456748962\n",
      "Training Accuracy per 5000 steps: 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [06:06<00:00, 14.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 14: 64.46886446886447\n",
      "Training Loss Epoch: 0.6517010973050044\n",
      "Training Accuracy Epoch: 64.46886446886447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:14<05:54, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6445025205612183\n",
      "Training Accuracy per 5000 steps: 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [06:11<00:00, 14.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 15: 63.36996336996337\n",
      "Training Loss Epoch: 0.6507597840749301\n",
      "Training Accuracy Epoch: 63.36996336996337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:14<06:13, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6512166857719421\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [04:14<00:00,  9.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 16: 63.30891330891331\n",
      "Training Loss Epoch: 0.6493170330157647\n",
      "Training Accuracy Epoch: 63.30891330891331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:05<02:27,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6707883477210999\n",
      "Training Accuracy per 5000 steps: 57.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:29<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 17: 64.59096459096459\n",
      "Training Loss Epoch: 0.6501165078236506\n",
      "Training Accuracy Epoch: 64.59096459096459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:04<01:51,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6782494783401489\n",
      "Training Accuracy per 5000 steps: 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:33<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 18: 63.492063492063494\n",
      "Training Loss Epoch: 0.6490718836967762\n",
      "Training Accuracy Epoch: 63.492063492063494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:31,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6708793640136719\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:29<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 19: 64.77411477411478\n",
      "Training Loss Epoch: 0.6494724108622625\n",
      "Training Accuracy Epoch: 64.77411477411478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:05<02:18,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6474196910858154\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:55<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 20: 63.614163614163616\n",
      "Training Loss Epoch: 0.6480908325085273\n",
      "Training Accuracy Epoch: 63.614163614163616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:05<02:25,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6238331198692322\n",
      "Training Accuracy per 5000 steps: 71.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:36<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 21: 64.71306471306471\n",
      "Training Loss Epoch: 0.6439842146176559\n",
      "Training Accuracy Epoch: 64.71306471306471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:32,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6204677820205688\n",
      "Training Accuracy per 5000 steps: 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:32<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 22: 65.44566544566544\n",
      "Training Loss Epoch: 0.6435632293040936\n",
      "Training Accuracy Epoch: 65.44566544566544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:31,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7089557647705078\n",
      "Training Accuracy per 5000 steps: 54.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:32<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 23: 63.614163614163616\n",
      "Training Loss Epoch: 0.6479041966108176\n",
      "Training Accuracy Epoch: 63.614163614163616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:27,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6815110445022583\n",
      "Training Accuracy per 5000 steps: 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:29<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 24: 64.77411477411478\n",
      "Training Loss Epoch: 0.6455508929032546\n",
      "Training Accuracy Epoch: 64.77411477411478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:33,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6343772411346436\n",
      "Training Accuracy per 5000 steps: 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:29<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 25: 64.59096459096459\n",
      "Training Loss Epoch: 0.6455177939855136\n",
      "Training Accuracy Epoch: 64.59096459096459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:27,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.637758195400238\n",
      "Training Accuracy per 5000 steps: 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:34<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 26: 64.34676434676435\n",
      "Training Loss Epoch: 0.6442531874546638\n",
      "Training Accuracy Epoch: 64.34676434676435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:03<01:36,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6386380791664124\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [02:11<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 27: 65.56776556776556\n",
      "Training Loss Epoch: 0.6374505414412572\n",
      "Training Accuracy Epoch: 65.56776556776556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:11,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6439143419265747\n",
      "Training Accuracy per 5000 steps: 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:15<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 28: 63.614163614163616\n",
      "Training Loss Epoch: 0.6458763411411872\n",
      "Training Accuracy Epoch: 63.614163614163616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:02<01:10,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6600029468536377\n",
      "Training Accuracy per 5000 steps: 64.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:26<00:00,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 29: 63.98046398046398\n",
      "Training Loss Epoch: 0.6436567489917462\n",
      "Training Accuracy Epoch: 63.98046398046398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation def\n",
    "VALID_BATCH_SIZE = 1 #set to 1 for printing of individual wrong predictions\n",
    "\n",
    "#detokenize def\n",
    "def DBDetokenize(a):\n",
    "    a_orig = [tokenizer.decode(x) for x in a['ids'].squeeze().tolist() if x != 0]\n",
    "    a_orig = ([x.replace(' ' , '') for x in a_orig])\n",
    "    return \" \".join(a_orig)\n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    tr_loss = 0 #added\n",
    "    nb_tr_steps = 0 #added\n",
    "    nb_tr_examples = 0 #added\n",
    "    max_wrong_outputs = 10\n",
    "    wrong_outputs = 0\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask)#.squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "            #print individual wrong responses to file\n",
    "            if VALID_BATCH_SIZE == 1 and wrong_outputs < max_wrong_outputs: \n",
    "                wrong_outputs += 1\n",
    "                path = '/home/pd/summar   ies/yelp_summary_13Mar23.txt'\n",
    "                with open(path,'a') as f:\n",
    "                    f.write(DBDetokenize(data))\n",
    "                    f.write(f'Should be: {1 if targets.item() else 5}')\n",
    "                    f.write('\\n')\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pd/NNBasics/venv_NNBasics/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 0.4546707570552826\n",
      "Validation Accuracy per 100 steps: 100.0\n",
      "Validation Loss Epoch: 0.6451624179395233\n",
      "Validation Accuracy Epoch: 64.8780487804878\n",
      "Accuracy on test data = 64.88%\n"
     ]
    }
   ],
   "source": [
    "#validation run\n",
    "acc = valid(model, testing_loader)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/pd/models/yelp_sentiment_vocab.bin',)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model_file = '/home/pd/models/yelp_sentiment.bin'\n",
    "output_vocab_file = '/home/pd/models/yelp_sentiment_vocab.bin'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/pd/NNBasics/venv_NNBasics/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#get raw dbert\n",
    "dbase = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "a = next(iter(single_loader))\n",
    "def get_raw_dbert(a, dbase): \n",
    "    return dbase(input_ids=a['ids'],attention_mask=a['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:16:50.800780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 10:16:52.413475: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pd/NNBasics/NNBasics/notebooks/Transformer_Sentiment.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/pd/NNBasics/NNBasics/notebooks/Transformer_Sentiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m exec(\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m/home/pd/NNBasics/NNBasics/src/PostBertEngine.py\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mread())\n",
      "File \u001b[0;32m<string>:3\u001b[0m\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logging,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/transformers/dependency_versions_check.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     20\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/transformers/utils/__init__.py:34\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     28\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     ContextManagers,\n\u001b[1;32m     36\u001b[0m     ExplicitEnum,\n\u001b[1;32m     37\u001b[0m     ModelOutput,\n\u001b[1;32m     38\u001b[0m     PaddingStrategy,\n\u001b[1;32m     39\u001b[0m     TensorType,\n\u001b[1;32m     40\u001b[0m     cached_property,\n\u001b[1;32m     41\u001b[0m     can_return_loss,\n\u001b[1;32m     42\u001b[0m     expand_dims,\n\u001b[1;32m     43\u001b[0m     find_labels,\n\u001b[1;32m     44\u001b[0m     flatten_dict,\n\u001b[1;32m     45\u001b[0m     is_jax_tensor,\n\u001b[1;32m     46\u001b[0m     is_numpy_array,\n\u001b[1;32m     47\u001b[0m     is_tensor,\n\u001b[1;32m     48\u001b[0m     is_tf_tensor,\n\u001b[1;32m     49\u001b[0m     is_torch_device,\n\u001b[1;32m     50\u001b[0m     is_torch_dtype,\n\u001b[1;32m     51\u001b[0m     is_torch_tensor,\n\u001b[1;32m     52\u001b[0m     reshape,\n\u001b[1;32m     53\u001b[0m     squeeze,\n\u001b[1;32m     54\u001b[0m     tensor_size,\n\u001b[1;32m     55\u001b[0m     to_numpy,\n\u001b[1;32m     56\u001b[0m     to_py_obj,\n\u001b[1;32m     57\u001b[0m     transpose,\n\u001b[1;32m     58\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     61\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     62\u001b[0m     DISABLE_TELEMETRY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     send_example_telemetry,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     91\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     92\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     torch_version,\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/transformers/utils/generic.py:33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     36\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/NNBasics/venv_NNBasics/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tensorflow_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[39m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exec(open('/home/pd/NNBasics/NNBasics/src/PostBertEngine.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1638, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('/home/pd/datasets/yelp_reviews/yelp_reviews_targets_1024.pt')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/pd/NNBasics/NNBasics/src/Preprocess.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CSV_PATH = \"/home/pd/datasets/yelp_reviews_temp/yelp_reviews_2048.csv\"\n",
    "DATA_PATH = \"/home/pd/datasets/yelp_reviews/yelp_reviews.json\"\n",
    "SUMMARY_PATH = '/home/pd/summaries/yelp_summary_13Mar23.txt'\n",
    "OUTPUT_MODEL_PATH = '/home/pd/models/yelp_sentiment.bin'\n",
    "OUTPUT_VOCAB_PATH = '/home/pd/models/yelp_sentiment_vocab.bin'\n",
    "BERT_OUT_PATH = '/home/pd/datasets/yelp_reviews_temp/yelp_reviews_postBERT_1024.pt'\n",
    "TARG_OUT_PATH = '/home/pd/datasets/yelp_reviews_temp/yelp_reviews_targets_1024.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramd = dict()\n",
    "paramd['data_path'] = DATA_PATH\n",
    "paramd['out_path'] = \"/home/pd/datasets/yelp_reviews_temp/yelp_reviews_2048.csv\"\n",
    "paramd['max_words'] = 64\n",
    "paramd['low_star_rev_lim'] = 100\n",
    "paramd['tot_rev_lim'] = float('inf')\n",
    "paramd['debug_path'] = '/home/pd/summaries/yelp_temp.txt'\n",
    "\n",
    "ypp = YelpPreprocess(**paramd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pd/datasets/yelp_reviews/yelp_reviews.json'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypp.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = ypp.json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    stat = 50\n",
    "\n",
    "    def __init__(self,inp):\n",
    "        self.inp = inp\n",
    "\n",
    "    def square(self):\n",
    "        self.inp = self.inp**2\n",
    "\n",
    "    @staticmethod\n",
    "    def buzz(a,b):\n",
    "        return a + b\n",
    "    \n",
    "    def add(self):\n",
    "        self.inp = self.buzz(self.inp,self.inp)\n",
    "\n",
    "    def addstat(self):\n",
    "        self.inp = self.inp + self.stat\n",
    "\n",
    "class foo():\n",
    "\n",
    "    def __init__(self,inp):\n",
    "        self.inp = inp\n",
    "\n",
    "    def square_obj(self):\n",
    "        self.inp.square()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model(5)\n",
    "a.addstat()\n",
    "a.inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CSV_PATH = \"/home/pd/datasets/yelp_reviews/yelp_reviews_2048.csv\"\n",
    "DATA_PATH = \"/home/pd/datasets/yelp_reviews/yelp_reviews.json\"\n",
    "SUMMARY_PATH = '/home/pd/summaries/yelp_summary_24Mar23.txt'\n",
    "OUTPUT_MODEL_PATH = '/home/pd/models/yelp_sentiment.bin'\n",
    "OUTPUT_VOCAB_PATH = '/home/pd/models/yelp_sentiment_vocab.bin'\n",
    "BERT_OUT_PATH = '/home/pd/datasets/yelp_reviews/yelp_reviews_postBERT_1024.pt'\n",
    "TARG_OUT_PATH = '/home/pd/datasets/yelp_reviews/yelp_reviews_targets_1024.pt'\n",
    "\n",
    "\n",
    "SAVE_BERT_LAYER_OUT = False\n",
    "FROM_BERT_LAYER_OUT = not SAVE_BERT_LAYER_OUT\n",
    "\n",
    "FROM_CSV_CONDENSED = True #otherwise getting from full json file\n",
    "\n",
    "#read-in data\n",
    "lowstar_review_limit = 128\n",
    "review_limit = float('inf')\n",
    "sample_per_cat = 128\n",
    "max_num_words = 50\n",
    "\n",
    "#init train/test params\n",
    "MAX_LEN = 64\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 1 #set to 1 for printing of individual wrong predictions\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05\n",
    "AUTO_SCALE_GRAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/pd/NNBasics/NNBasics/notebooks/Transformer_Sentiment.ipynb Cell 28\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/pd/NNBasics/NNBasics/notebooks/Transformer_Sentiment.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mModel\u001b[39;00m \u001b[39mimport\u001b[39;00m DBertMultiCat\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Model'"
     ]
    }
   ],
   "source": [
    "from Model import DBertMultiCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "a = None\n",
    "if not a:\n",
    "    print('hi')\n",
    "else:\n",
    "    print('you')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNBasics_venv2",
   "language": "python",
   "name": "nnbasics_venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54933d5d0454cb54ea8cf4e7b3c099269c704adbee2a5b35f5a5ea4d0f5219ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
